{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ae3cba47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Loss = 0.9247\n",
      "Epoch 20: Loss = 0.1225\n",
      "Epoch 30: Loss = 0.0432\n",
      "Epoch 40: Loss = 0.0228\n",
      "Epoch 50: Loss = 0.0142\n",
      "வணக்கம்\n",
      "நீங்கள் எப்படி இருக்கிறீர்கள்\n",
      "நான் நன்றாக இருக்கிறேன்\n",
      "கழிப்பறை எங்கே உள்ளது\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "data = [\n",
    "    (\"hello\", \"வணக்கம்\"),\n",
    "    (\"how are you\", \"நீங்கள் எப்படி இருக்கிறீர்கள்\"),\n",
    "    (\"thank you\", \"நன்றி\"),\n",
    "    (\"good morning\", \"காலை வணக்கம்\"),\n",
    "    (\"good night\", \"இனிய இரவு\"),\n",
    "    (\"what is your name\", \"உங்கள் பெயர் என்ன\"),\n",
    "    (\"i am fine\", \"நான் நன்றாக இருக்கிறேன்\"),\n",
    "    (\"where are you\", \"நீங்கள் எங்கே இருக்கிறீர்கள்\"),\n",
    "    (\"nice to meet you\", \"உங்களை சந்தித்ததில் மகிழ்ச்சி\"),\n",
    "    (\"i love you\", \"நான் உன்னை நேசிக்கிறேன்\"),\n",
    "    (\"please sit down\", \"தயவுசெய்து உட்காருங்கள்\"),\n",
    "    (\"come here\", \"இங்கே வாருங்கள்\"),\n",
    "    (\"go there\", \"அங்கே செல்லுங்கள்\"),\n",
    "    (\"do you speak english\", \"நீங்கள் ஆங்கிலம் பேசுகிறீர்களா\"),\n",
    "    (\"i don't understand\", \"எனக்குப் புரியவில்லை\"),\n",
    "    (\"can you help me\", \"நீங்கள் எனக்கு உதவ முடியுமா\"),\n",
    "    (\"i am hungry\", \"எனக்கு பசிக்கிறது\"),\n",
    "    (\"this is my friend\", \"இவர் என் நண்பர்\"),\n",
    "    (\"where is the bathroom\", \"கழிப்பறை எங்கே உள்ளது\"),\n",
    "    (\"i am learning tamil\", \"நான் தமிழைக் கற்றுக்கொண்டு இருக்கிறேன்\")\n",
    "]\n",
    "\n",
    "def build_vocab(sentences):\n",
    "    vocab = {\"<pad>\": 0, \"<sos>\": 1, \"<eos>\": 2}\n",
    "    idx = 3\n",
    "    for sentence in sentences:\n",
    "        for word in sentence.split():\n",
    "            if word not in vocab:\n",
    "                vocab[word] = idx\n",
    "                idx += 1\n",
    "    return vocab\n",
    "\n",
    "src_vocab = build_vocab([src for src, _ in data])\n",
    "trg_vocab = build_vocab([trg for _, trg in data])\n",
    "inv_trg_vocab = {v: k for k, v in trg_vocab.items()}\n",
    "\n",
    "def encode(sentence, vocab):\n",
    "    return [vocab[\"<sos>\"]] + [vocab[word] for word in sentence.split()] + [vocab[\"<eos>\"]]\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim)\n",
    "\n",
    "    def forward(self, src):\n",
    "        embedded = self.embedding(src)\n",
    "        outputs, hidden = self.gru(embedded)\n",
    "        return hidden\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, hid_dim):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        self.gru = nn.GRU(emb_dim, hid_dim)\n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        input = input.unsqueeze(0)\n",
    "        embedded = self.embedding(input)\n",
    "        output, hidden = self.gru(embedded, hidden)\n",
    "        prediction = self.fc_out(output.squeeze(0))\n",
    "        return prediction.squeeze(0), hidden\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, src, trg, teacher_forcing_ratio=0.5):\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.fc_out.out_features\n",
    "        outputs = torch.zeros(trg_len, trg_vocab_size).to(device)\n",
    "        hidden = self.encoder(src)\n",
    "        input = trg[0].unsqueeze(0)\n",
    "        for t in range(1, trg_len):\n",
    "            output, hidden = self.decoder(input, hidden)\n",
    "            outputs[t] = output\n",
    "            top1 = output.argmax(0)\n",
    "            input = trg[t].unsqueeze(0) if random.random() < teacher_forcing_ratio else top1.unsqueeze(0)\n",
    "        return outputs\n",
    "\n",
    "INPUT_DIM = len(src_vocab)\n",
    "OUTPUT_DIM = len(trg_vocab)\n",
    "EMB_DIM = 64\n",
    "HID_DIM = 128\n",
    "\n",
    "enc = Encoder(INPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, EMB_DIM, HID_DIM).to(device)\n",
    "model = Seq2Seq(enc, dec).to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(n_epochs=50):\n",
    "    model.train()\n",
    "    for epoch in range(n_epochs):\n",
    "        total_loss = 0\n",
    "        for src_sent, trg_sent in data:\n",
    "            src_tensor = torch.tensor(encode(src_sent, src_vocab), dtype=torch.long).unsqueeze(1).to(device)\n",
    "            trg_tensor = torch.tensor(encode(trg_sent, trg_vocab), dtype=torch.long).to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(src_tensor, trg_tensor)\n",
    "            output_dim = output.shape[-1]\n",
    "            loss = criterion(output[1:].view(-1, output_dim), trg_tensor[1:])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}: Loss = {total_loss/len(data):.4f}\")\n",
    "\n",
    "def translate(sentence):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        src_tensor = torch.tensor(encode(sentence, src_vocab), dtype=torch.long).unsqueeze(1).to(device)\n",
    "        hidden = model.encoder(src_tensor)\n",
    "        input = torch.tensor([trg_vocab[\"<sos>\"]], dtype=torch.long).to(device)\n",
    "        result = []\n",
    "        for _ in range(20):\n",
    "            output, hidden = model.decoder(input, hidden)\n",
    "            top1 = output.argmax(0).item()\n",
    "            if top1 == trg_vocab[\"<eos>\"]:\n",
    "                break\n",
    "            result.append(inv_trg_vocab[top1])\n",
    "            input = torch.tensor([top1], dtype=torch.long).to(device)\n",
    "        return \" \".join(result)\n",
    "\n",
    "train()\n",
    "print(translate(\"hello\"))\n",
    "print(translate(\"how are you\"))\n",
    "print(translate(\"i am fine\"))\n",
    "print(translate(\"where is the bathroom\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae0b1538",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
